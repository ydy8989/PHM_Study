# 1. Revisit Deep Neural Networks

## 1.1 Machine learning problem

**Classic Machine Learning?**

1. collect training data
   $$
   x = \{x_1, x_2, ...,x_N\}\\
   y = \{y_1, y_2, ..., y_N\}\\
   \mathcal{D} = \{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\}
   $$

2. Define functions
   $$
   output : f_{\theta}(x)\\
   Loss : L(f_\theta(x),y)
   $$

3. Learning/Training

   - find the optimal parameter

4. Predicting/Testing

   - Compute optimal function output

------

**Collect training data**

- 알아서....

**Define functions**

> - 모델을 정하고, Loss function을 정하는 과정
>
>   > 데이터와 모델, 그리고 loss function을 정하면 사실상 바꿀 것이 없음. (제약)
>
> - **Loss function** 
>   $$
>   Loss = L(f_\theta(x),y) = \sum_i L(f_\theta(x_i),y_i)
>   $$
>
> - 지금까지의 딥러닝 과정에서는 Loss function을 마음대로 사용할 수 없음. 왜??
>
>   **Why?** Back propagation 때문임. 역전파 과정이 진행되어야 loss 값을 구할 수 있기 때문임.
>
>   - 역전파 알고리즘은 수식 4개로 진행되는데, 이를 진행하기 위한 **2가지 가정**이 있음
>
>     > **Assumption 1.**) 전체 트레인 loss는 각 샘플별 loss의 합과 같다.
>
>     > **Assumption 2.**)  loss 함수를 구할 때, 네트워크의 **출력값과 정답값**만 가지고 계산한다.
>
>   - 이 두가지 가정이 안되면, Back propagation이 불가능

------

**Learning/Training**

> - loss를 정의하면, 이 loss를 minimize하는 파라미터 Theta를 찾는데...
>
> - 이 Theta를 찾는 방식은 대부분 경사하강법을 사용함(Optimal theory의 가장 기초)
>
> - Iterative method를 채택 : 한 단계씩 점점 가까워지는 방식
>
>   > - 여기서 두 가지 질문이 발생함
>   >
>   >   > 1. 어떻게 iterate 할꺼?
>   >   > 2. 언제 멈출꺼?
>   >
>   > - answer 1 : 로스값이 줄어드는 방향이면 무조건 그쪽으로 움직인다.
>   >
>   > - answer 2 : 움직여도 로스값이 변함없을 경우에 멈춤
>   >
>   > ------
>   >
>   > - 이런 식으로 theta를 바꾸긴 바꿔야하는데... Dimension 클수록 이런 문제가 더더더 발생
>   >
>   >   > 3. 어떻게 theta를 바꿔야 loss가 줄어들어?
>   > 
>   > - answer 3 :
>   >
>   >   - Taylor Expansion :  ![figure1](https://user-images.githubusercontent.com/38639633/61756223-f9242880-adf5-11e9-91a8-c490a9643dcf.png)
>   >   
>   >   - Approximation : 테일러 expansion처럼 다 확장시키는게 아니라 1차 미분계수만 구해서 계산하는 방식.
>   >   
>   >     ![figure2](https://user-images.githubusercontent.com/38639633/61756261-2244b900-adf6-11e9-898a-1211ed024431.png)
>   >   
>   >     Learning rate를 사용하여 조금씩 파라미터 값을 바꾸는 것은 로스 함수의 1차 미분항까지만 사용했기 때문에, 아주 좁은 영역(sample data의 인접 지역)에서만 감소 방향이 정확하기 때문임...
>   >
>   
> - 전체 데이터에 대한 로스 함수가 각 데이터 샘플에 대한 로스의 합으로 구성되어 있기에 미분 계산을 효율적으로 할 수 있다. 
>
> - 만약 곱으로 구성되어 있으면, 미분을 위해 모든 샘플의 결과를 메모리에 저장하여야 한다.
>
> - 원래는 모든 데이터에 대한 로스 미분값의 합을 구한 후 파라미터를 갱신해야 하지만, 배치 크기만큼만 로스 미분값의 합을 구한 후 파라미터를 갱신한다. (stochastic 경사하강) =>> 전체와 배치의 경사하강이 같을 거라는 기대

------

------

## 1.2 Loss function (*viewpoint I : Back-propagation*)

- **2가지 관점**
  1. 딥러닝 학습 시 **Back-propagation**이 잘 동작하는 관점 : **Cross Entropy**
  2. 네트워크 출력값이 **Continuous value**면 **Mean Square Error** and **Discrete**하면 **Cross Entropy**

> 이 두개를 쓰는 이유는 backpropagation을 사용하기 위한 가정 2가지가 충족되는 방식이기 때문에.

![1563866156888](https://user-images.githubusercontent.com/38639633/61756334-6fc12600-adf6-11e9-99d8-a72ffc61d4a7.png)

###  Type 1 : Mean Square Error / Quadratic loss

![1563866201260](https://user-images.githubusercontent.com/38639633/61756345-7fd90580-adf6-11e9-995a-4f075bf72064.png)


- 두 가지 케이스를 랜덤하게 초기값으로 잡고 그린 결과, 초기값에 따른 변화가 다름;

![1563866367891](https://user-images.githubusercontent.com/38639633/61756357-8a939a80-adf6-11e9-8596-c289e4c38efc.png)

- 보이는 것 처럼, weight와 bias 둘다 backpropagation 단계에서 미분값이 포함되어있음(시그마프라임(z))
- **초록박스**: 미분값이 있는애랑, 거의 없는애랑의 차이..



### Type 2 : Cross Entropy

- MSE와는 달리 CE는 출력 레이어에서의 에러값에 activation function의 미분값이 곱해지지 않아, gradient vanishing problem 문제가 발생하지 않는다(학습이 빨리된다 - 여기서 학습이 빨리된다는거는, 학습 완료로 만족할만한 수준까지 도달하는데 걸리는 시간이 짧다는 것임)
- 그러나 ***레이어가 여러개가 사용될 경우***에는 결국 activation function의 미분값이 계속해서 곱해지므로 gradient vanishing problem에서 완전히 자유로울 수는 없다. 
  - 이러한 관점에서 relu는 미분계수가 1 혹은 0이기 때문에, 레이어가 추가되어도, 학습이 초반부터 빠르게 진행가능함

- ***MSE(초록)와 CE(검정)의 차이*** : MSE는 처음부터, activation function의 도함수가 포함되어있다. 

![1563867933936](https://user-images.githubusercontent.com/38639633/61756368-92533f00-adf6-11e9-894b-92854f9e703f.png)

​	![1563868525864](https://user-images.githubusercontent.com/38639633/61756369-92533f00-adf6-11e9-90c1-f3667b15a497.png)



## 1.3 Loss function viewpoint II : Maximum likelihood

> 네트워크의 출력값에 대한 해석이 매우 중요함

- 목표는 우리가 정해놓은 확률 분포를 만드는 파라미터를 추정하는 것임을 인지해야함

  > ![1](https://user-images.githubusercontent.com/38639633/61759106-51f9be00-ae02-11e9-84ff-1e4f472ac6d1.PNG)
  >
  > 1.  y는 우리가 들고 있는 정답
  > 2. 모델(f(x)with parameter theta)를 통과한뒤 나온 f(x1)과 y를 비교
  > 3. 여기서 모델을 통과하면 (정해진)분포를 만들어내는 파라미터를 출력함
  >    1. ex)가우시안 분포일때 모델 출력값(파라미터)는 평균, 표준편차임
  > 4. 그걸로부터 가상의 분포를 만들고, y값을 그 분포에서 추출할 때, 높은 확률이 나오게끔 학습진행

- log씌운 이유는 `backpropagation`때문에

- y값이 최대가 되게끔하는 분포를 학습을 통해서 만들고, 분포에서 샘플링을 통해 생성



**i.i.d Condition**

- Assumption 1: **i**ndependence

  - $$
    p(y|f_\theta(x)) = \Pi_ip_{d_i}(y|f_\theta(x_i))
    $$

  - 각 샘플별 prob의 곱은 전체 데이터의 prob과 같다.

- Assumption 2 : **I**dentical **D**istribution

  - 각 샘플별로 다른 distribution을 적용할 수는 있지만, 모든 샘플의 distribution 종류를 같은걸로 하겠다.



**Loss function**

아무튼, loss function을 
$$
-log(p(y|f_\theta(x))) = -\sum_i log(p(y_i|f_\theta(x_i)))
$$
처럼 loss function을 설정한 결과, 위의 Assumption 1,2을 만족하더라~



**Univariate cases and Multivarate cases**

![2](https://user-images.githubusercontent.com/38639633/61765361-b83d0b80-ae17-11e9-8fe9-964dc07c40d0.png)



